{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b56bc897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/order1TEST/data/order1TEST.csv' to '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/order1TEST/data/order1TEST.csv'\n",
      "Renaming completed.\n"
     ]
    }
   ],
   "source": [
    "#This script renames all of the data within the directory so that it can be better analyzed\n",
    "import os\n",
    "\n",
    "# Base directory path\n",
    "base_dir = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test'\n",
    "\n",
    "# Traverse through all the folders in the base directory\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    # Check if the directory is named 'data'\n",
    "    if os.path.basename(root) == 'data':\n",
    "        # Get the parent folder name (subfolder name)\n",
    "        parent_folder_name = os.path.basename(os.path.dirname(root))\n",
    "        \n",
    "        # Iterate over all files in the 'data' folder\n",
    "        for file_name in files:\n",
    "            # Construct the full path to the current file\n",
    "            old_file_path = os.path.join(root, file_name)\n",
    "            \n",
    "            # Construct the new file path with the parent folder name\n",
    "            new_file_name = f\"{parent_folder_name}{os.path.splitext(file_name)[1]}\"\n",
    "            new_file_path = os.path.join(root, new_file_name)\n",
    "            \n",
    "            # Rename the file\n",
    "            os.rename(old_file_path, new_file_path)\n",
    "            print(f\"Renamed '{old_file_path}' to '{new_file_path}'\")\n",
    "\n",
    "print(\"Renaming completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8541e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing file: order1TEST.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Function to check if the stimulus is the trial fixation cross\n",
    "def is_trial_fixation_cross(stimulus):\n",
    "    if pd.notna(stimulus):\n",
    "        # Remove whitespace and quotes\n",
    "        stimulus_stripped = ''.join(stimulus.replace('\"', '').replace(\"'\", '').split())\n",
    "        # Check if the stimulus matches the trial fixation cross\n",
    "        if stimulus_stripped == '<pstyle=font-size:48px;><br><br>+<br><br></p>':\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to check if the stimulus is the green fixation cross\n",
    "def is_green_fixation_cross(stimulus):\n",
    "    if pd.notna(stimulus):\n",
    "        if '+' in stimulus and 'color:#1a851a' in stimulus:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to check if the stimulus is an instruction screen\n",
    "def is_instruction_screen(stimulus):\n",
    "    if pd.notna(stimulus):\n",
    "        if 'Press enter to begin the trials' in stimulus or 'Please look at the fixation cross' in stimulus:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Define the function to process CSV files\n",
    "def process_csv(file_path, output_dir, image_output_dir):\n",
    "    filename = os.path.basename(file_path)\n",
    "    print(f\"\\nProcessing file: {filename}\")\n",
    "\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path, encoding='utf-8')\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filename}: {e}\")\n",
    "        return\n",
    "\n",
    "    # Verify the required columns exist\n",
    "    required_columns = ['trial_type', 'trial_index', 'rt', 'stimulus', 'response']\n",
    "    if not all(column in df.columns for column in required_columns):\n",
    "        print(f\"File {filename} is missing required columns. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # Define the practice trials end marker\n",
    "    practice_end_pattern = r'The practice trials have been completed.*?Again, please respond as quickly and accurately as possible'\n",
    "\n",
    "    # Find the index where the practice trials end\n",
    "    practice_end_indices = df[df['stimulus'].str.contains(practice_end_pattern, regex=True, na=False)].index\n",
    "    if len(practice_end_indices) == 0:\n",
    "        print(f\"Practice trials end marker not found in {filename}. Skipping.\")\n",
    "        return\n",
    "    else:\n",
    "        practice_end_index = practice_end_indices[0]\n",
    "\n",
    "    # Extract trials after the practice trials\n",
    "    experiment_df = df.loc[practice_end_index + 1:].reset_index(drop=True)\n",
    "\n",
    "    # Initialize variables\n",
    "    current_trial = 0\n",
    "    in_trial = False\n",
    "    trial_data = []\n",
    "    image_trial_data = []\n",
    "    response_collected = False\n",
    "    is_image_trial = False\n",
    "    response_phase = 'NO RESPONSE'\n",
    "    response_rt = None\n",
    "    response_response = None\n",
    "    stimulus_content = None\n",
    "\n",
    "    # Iterate over the rows\n",
    "    for idx, row in experiment_df.iterrows():\n",
    "        stimulus = row['stimulus']\n",
    "        response = row['response']\n",
    "        rt = row['rt']\n",
    "        trial_index = row['trial_index']\n",
    "\n",
    "        # Skip instruction screens\n",
    "        if is_instruction_screen(stimulus):\n",
    "            continue\n",
    "\n",
    "        # Skip until we find the first trial fixation cross\n",
    "        if not in_trial:\n",
    "            if is_trial_fixation_cross(stimulus):\n",
    "                in_trial = True\n",
    "                current_trial += 1\n",
    "                stimulus_content = None\n",
    "                response_collected = False\n",
    "                is_image_trial = False\n",
    "                response_phase = 'NO RESPONSE'\n",
    "                response_rt = None\n",
    "                response_response = None\n",
    "            continue\n",
    "\n",
    "        # Check for green fixation cross (marks the end of the trial)\n",
    "        if is_green_fixation_cross(stimulus):\n",
    "            if in_trial:\n",
    "                trial_info = {\n",
    "                    'Trial': current_trial,\n",
    "                    'Response': response_response if response_collected else None,\n",
    "                    'RT': response_rt if response_collected else None,\n",
    "                    'Stimulus': stimulus_content,\n",
    "                    'Response Time Category': response_phase\n",
    "                }\n",
    "                if is_image_trial:\n",
    "                    image_trial_data.append(trial_info)\n",
    "                else:\n",
    "                    trial_data.append(trial_info)\n",
    "                in_trial = False\n",
    "            continue\n",
    "\n",
    "        if in_trial:\n",
    "            if pd.notna(stimulus) and ('<img' in stimulus or 'img' in stimulus):\n",
    "                is_image_trial = True\n",
    "\n",
    "            phase = None\n",
    "            if pd.notna(stimulus):\n",
    "                if '###' in stimulus:\n",
    "                    phase = 'MASK'\n",
    "                elif '+' in stimulus and 'color:red' in stimulus:\n",
    "                    phase = 'FIXATION'\n",
    "                elif '<p style=' in stimulus:\n",
    "                    phase = 'WORD'\n",
    "                    word_match = re.search(r'<p style=font-size:48px;><br><br>\\s*(.*?)\\s*<br><br></p>', stimulus)\n",
    "                    if word_match:\n",
    "                        stimulus_content = word_match.group(1).strip()\n",
    "\n",
    "            if not response_collected and pd.notna(response) and pd.notna(rt):\n",
    "                if not is_green_fixation_cross(stimulus):\n",
    "                    response_collected = True\n",
    "                    response_rt = rt\n",
    "                    response_response = response\n",
    "                    response_phase = phase\n",
    "\n",
    "    if in_trial:\n",
    "        trial_info = {\n",
    "            'Trial': current_trial,\n",
    "            'Response': response_response if response_collected else None,\n",
    "            'RT': response_rt if response_collected else None,\n",
    "            'Stimulus': stimulus_content,\n",
    "            'Response Time Category': response_phase\n",
    "        }\n",
    "        if is_image_trial:\n",
    "            image_trial_data.append(trial_info)\n",
    "        else:\n",
    "            trial_data.append(trial_info)\n",
    "\n",
    "    if trial_data:\n",
    "        paired_trial_data = []\n",
    "        for i in range(0, len(trial_data), 2):\n",
    "            trial1 = trial_data[i]\n",
    "            trial2 = trial_data[i+1] if i+1 < len(trial_data) else None\n",
    "            paired_info = {\n",
    "                'Trial1': trial1['Trial'],\n",
    "                'Response1': trial1['Response'],\n",
    "                'RT1': trial1['RT'],\n",
    "                'Stimulus1': trial1['Stimulus'],\n",
    "                'Response Time Category1': trial1['Response Time Category'],\n",
    "                'Trial2': trial2['Trial'] if trial2 else None,\n",
    "                'Response2': trial2['Response'] if trial2 else None,\n",
    "                'RT2': trial2['RT'] if trial2 else None,\n",
    "                'Stimulus2': trial2['Stimulus'] if trial2 else None,\n",
    "                'Response Time Category2': trial2['Response Time Category'] if trial2 else None\n",
    "            }\n",
    "            paired_trial_data.append(paired_info)\n",
    "\n",
    "        output_df = pd.DataFrame(paired_trial_data)\n",
    "        output_file = os.path.join(output_dir, f\"{os.path.splitext(filename)[0]}_responses.csv\")\n",
    "        output_df.to_csv(output_file, index=False)\n",
    "\n",
    "    if image_trial_data:\n",
    "        image_output_df = pd.DataFrame(image_trial_data)\n",
    "        image_output_file = os.path.join(image_output_dir, f\"{os.path.splitext(filename)[0]}_image_trials.csv\")\n",
    "        image_output_df.to_csv(image_output_file, index=False)\n",
    "\n",
    "# Main function to search for data folders and process files\n",
    "def search_and_process_data(input_dir, output_dir, image_output_dir):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        if 'data' in dirs:\n",
    "            data_folder = os.path.join(root, 'data')\n",
    "            for filename in os.listdir(data_folder):\n",
    "                if filename.lower().endswith('.csv'):\n",
    "                    file_path = os.path.join(data_folder, filename)\n",
    "                    process_csv(file_path, output_dir, image_output_dir)\n",
    "\n",
    "# Set the input and output directories\n",
    "input_dir = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test'\n",
    "output_dir = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/SessionFiles'\n",
    "image_output_dir = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/CatchImages'\n",
    "\n",
    "# Ensure the output directories exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(image_output_dir, exist_ok=True)\n",
    "\n",
    "# Start the search and process\n",
    "search_and_process_data(input_dir, output_dir, image_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40894b92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files found: ['/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/CatchImages/order1TESTB_image_trials.csv']\n",
      "Processing file: /Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/CatchImages/order1TESTB_image_trials.csv\n",
      "   Trial Response     RT  Stimulus Response Time Category\n",
      "0      9        m   39.0       NaN               FIXATION\n",
      "1     20        m  136.0       NaN               FIXATION\n",
      "2     43        m  261.0       NaN               FIXATION\n",
      "3     46        m  929.0       NaN               FIXATION\n",
      "4     69        z   64.0       NaN                    NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_41e83\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_41e83_level0_col0\" class=\"col_heading level0 col0\" >Filename</th>\n",
       "      <th id=\"T_41e83_level0_col1\" class=\"col_heading level0 col1\" >Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_41e83_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_41e83_row0_col0\" class=\"data row0 col0\" >order1TESTB_image_trials.csv</td>\n",
       "      <td id=\"T_41e83_row0_col1\" class=\"data row0 col1\" >90.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x123299950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory containing your CSV files\n",
    "directory = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/CatchImages/'\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "file_pattern = os.path.join(directory, '*.csv')\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "# Print out the list of files\n",
    "print(f\"Files found: {files}\")\n",
    "\n",
    "# Answer key for the first 10 responses\n",
    "default_answer_key = {\n",
    "    0: 'z',\n",
    "    1: 'z',\n",
    "    2: 'm',\n",
    "    3: 'z',\n",
    "    4: 'm',\n",
    "    5: 'm',\n",
    "    6: 'z',\n",
    "    7: 'm',\n",
    "    8: 'z',\n",
    "    9: 'm'\n",
    "}\n",
    "\n",
    "# Reversed answer key for files with a capital 'B' in the name\n",
    "reversed_answer_key = {\n",
    "    0: 'm',\n",
    "    1: 'm',\n",
    "    2: 'z',\n",
    "    3: 'm',\n",
    "    4: 'z',\n",
    "    5: 'z',\n",
    "    6: 'm',\n",
    "    7: 'z',\n",
    "    8: 'm',\n",
    "    9: 'z'\n",
    "}\n",
    "\n",
    "# List to store results\n",
    "data_list = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        print(f\"Processing file: {file}\")  # Check which file is being processed\n",
    "        print(df.head())  # Preview the first few rows\n",
    "        \n",
    "        # Take the first 10 responses\n",
    "        df_subset = df.head(10).copy()\n",
    "        \n",
    "        # Check if the file name contains a capital 'B' and select the appropriate answer key\n",
    "        if 'B' in os.path.basename(file):\n",
    "            answer_key = reversed_answer_key\n",
    "        else:\n",
    "            answer_key = default_answer_key\n",
    "        \n",
    "        if not df_subset.empty:\n",
    "            # Map the index (0-9) to the correct responses\n",
    "            df_subset['CorrectResponse'] = df_subset.index.map(answer_key)\n",
    "            \n",
    "            # Compare the participant's response to the correct response\n",
    "            df_subset['IsCorrect'] = df_subset['Response'] == df_subset['CorrectResponse']\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            total_trials = len(df_subset)\n",
    "            correct_trials = df_subset['IsCorrect'].sum()\n",
    "            accuracy = (correct_trials / total_trials) * 100 if total_trials > 0 else 0\n",
    "            \n",
    "            # Append the results\n",
    "            data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': accuracy})\n",
    "        else:\n",
    "            data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': 'No Data'})\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file}: {e}\")\n",
    "        data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': f'Error: {e}'})\n",
    "        \n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(data_list)\n",
    "\n",
    "# Function to highlight rows with accuracy below 80%\n",
    "def highlight_low_accuracy(row):\n",
    "    if isinstance(row['Accuracy (%)'], (int, float)):\n",
    "        if row['Accuracy (%)'] < 80:\n",
    "            return ['background-color: red'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply the styling to the DataFrame\n",
    "styled_df = results_df.style.apply(highlight_low_accuracy, axis=1)\n",
    "\n",
    "# Explicitly display the styled DataFrame\n",
    "display(styled_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6251ce06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved accuracy file for order1aB_responses.csv at /Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/Accuracy/order1aB_accuracy.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths\n",
    "base_dir = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/'\n",
    "session_files_dir = os.path.join(base_dir, 'SessionFiles')\n",
    "accuracy_output_dir = os.path.join(base_dir, 'Accuracy')\n",
    "\n",
    "# Ensure accuracy output directory exists\n",
    "if not os.path.exists(accuracy_output_dir):\n",
    "    os.makedirs(accuracy_output_dir)\n",
    "\n",
    "def process_responses_file(responses_file):\n",
    "    # Load the responses CSV\n",
    "    responses_path = os.path.join(session_files_dir, responses_file)\n",
    "    responses_df = pd.read_csv(responses_path)\n",
    "\n",
    "    # Extract folder name (without \"_responses.csv\") from the responses file\n",
    "    folder_name = responses_file.replace('_responses.csv', '')\n",
    "\n",
    "    # Check if it has a capital B\n",
    "    reverse_flag = 'B' in folder_name\n",
    "\n",
    "    # Construct the corresponding folder path in Lexical_Decisions_Run\n",
    "    matching_folder = folder_name  # Use the exact folder name including any capital B\n",
    "    folder_path = os.path.join(base_dir, matching_folder)\n",
    "\n",
    "    # Determine the corresponding HTML1{letter}ALL.csv\n",
    "    csv_letter = folder_name[folder_name.index('order') + len('order'):folder_name.index('a') + 1]\n",
    "    matching_csv = f'HTML{csv_letter}ALL.csv'\n",
    "    matching_csv_path = os.path.join(folder_path, matching_csv)\n",
    "\n",
    "    # Check if the CSV exists in the folder\n",
    "    if not os.path.exists(matching_csv_path):\n",
    "        print(f\"File {matching_csv_path} not found. Skipping {responses_file}.\")\n",
    "        return\n",
    "\n",
    "    # Load the HTML CSV\n",
    "    html_df = pd.read_csv(matching_csv_path)\n",
    "\n",
    "    # Initialize accuracy columns\n",
    "    responses_df['Accuracy1'] = 'no'\n",
    "    responses_df['Accuracy2'] = 'no'\n",
    "\n",
    "    # Reverse correct responses if needed\n",
    "    if reverse_flag:\n",
    "        html_df['Correct1'] = html_df['Correct1'].replace({'z': 'm', 'm': 'z'})\n",
    "        html_df['Correct2'] = html_df['Correct2'].replace({'z': 'm', 'm': 'z'})\n",
    "\n",
    "    # Compare Correct1 and Correct2 with Response1 and Response2\n",
    "    responses_df['Accuracy1'] = responses_df.apply(lambda row: 'yes' if row['Response1'] == html_df.loc[row.name, 'Correct1'] else 'no', axis=1)\n",
    "    responses_df['Accuracy2'] = responses_df.apply(lambda row: 'yes' if row['Response2'] == html_df.loc[row.name, 'Correct2'] else 'no', axis=1)\n",
    "\n",
    "    # Save the results with accuracy columns\n",
    "    output_file = os.path.join(accuracy_output_dir, f'{folder_name}_accuracy.csv')\n",
    "    responses_df.to_csv(output_file, index=False)\n",
    "    print(f'Saved accuracy file for {responses_file} at {output_file}')\n",
    "\n",
    "# Process all response files in the SessionFiles directory\n",
    "for file in os.listdir(session_files_dir):\n",
    "    if file.endswith('_responses.csv'):\n",
    "        process_responses_file(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef1106e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_1e83b\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_1e83b_level0_col0\" class=\"col_heading level0 col0\" >Filename</th>\n",
       "      <th id=\"T_1e83b_level0_col1\" class=\"col_heading level0 col1\" >Accuracy (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_1e83b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_1e83b_row0_col0\" class=\"data row0 col0\" >order1aB_accuracy.csv</td>\n",
       "      <td id=\"T_1e83b_row0_col1\" class=\"data row0 col1\" >85.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x125555fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Directory containing your CSV files\n",
    "directory = '/Users/rhardy/Desktop/1021DataTest/Lexical_Decisions_Run_Test/Accuracy'\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "file_pattern = os.path.join(directory, '*.csv')\n",
    "files = glob.glob(file_pattern)\n",
    "\n",
    "# List to store results\n",
    "data_list = []\n",
    "\n",
    "for file in files:\n",
    "    try:\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Ensure required columns are present\n",
    "        if 'Accuracy1' in df.columns and 'Accuracy2' in df.columns:\n",
    "            # Count correct responses in 'Accuracy1' and 'Accuracy2'\n",
    "            correct1 = df['Accuracy1'].str.lower().eq('yes').sum()\n",
    "            correct2 = df['Accuracy2'].str.lower().eq('yes').sum()\n",
    "            total1 = df['Accuracy1'].notnull().sum()\n",
    "            total2 = df['Accuracy2'].notnull().sum()\n",
    "            \n",
    "            # Calculate total correct responses and total possible responses\n",
    "            total_correct = correct1 + correct2\n",
    "            total_possible = total1 + total2\n",
    "            accuracy = (total_correct / total_possible) * 100 if total_possible > 0 else 0\n",
    "            \n",
    "            # Append the results\n",
    "            data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': accuracy})\n",
    "        else:\n",
    "            data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': 'Columns Missing'})\n",
    "    except Exception as e:\n",
    "        data_list.append({'Filename': os.path.basename(file), 'Accuracy (%)': f'Error: {e}'})\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "results_df = pd.DataFrame(data_list)\n",
    "\n",
    "# Function to highlight rows with accuracy below 80%\n",
    "def highlight_low_accuracy(row):\n",
    "    if isinstance(row['Accuracy (%)'], (int, float)):\n",
    "        if row['Accuracy (%)'] < 80:\n",
    "            return ['background-color: red'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply the styling to the DataFrame\n",
    "styled_df = results_df.style.apply(highlight_low_accuracy, axis=1)\n",
    "\n",
    "# Display the styled DataFrame\n",
    "styled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4d587a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
